{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse \n",
    "class CF(object):\n",
    "    \"\"\"Khởi tạo class CF\n",
    "        Dữ liệu đầu vào của hàm khởi tạo class CF là ma trận Utility Y_data được lưu dưới dạng một ma trận với 3 cột, \n",
    "        k là số lượng các điểm lân cận được sử dụng để dự đoán kết quả. dist_func là hàm đó similarity giữa hai vectors, mặc định là cosine_similarity được lấy từ sklearn.metrics.pairwise. Bạn đọc cũng có thể thử với các giá trị k và hàm dist_func khác nhau. \n",
    "        Biến uuCF thể hiện việc đang sử dụng User-user CF (1) hay Item-item CF(0).\n",
    "    \"\"\"\n",
    "    def __init__(self, Y_data, k, dist_func = cosine_similarity, uuCF = 1):\n",
    "        self.uuCF = uuCF # user-user (1) or item-item (0) CF\n",
    "        self.Y_data = Y_data if uuCF else Y_data[:, [1, 0, 2]]\n",
    "        self.k = k\n",
    "        self.dist_func = dist_func\n",
    "        self.Ybar_data = None\n",
    "        # number of users and items. Remember to add 1 since id starts from 0\n",
    "        self.n_users = int(np.max(self.Y_data[:, 0])) + 1 \n",
    "        self.n_items = int(np.max(self.Y_data[:, 1])) + 1\n",
    "    \n",
    "    def add(self, new_data):\n",
    "        \"\"\"\n",
    "        Khi có dữ liệu mới, cập nhận Utility matrix bằng cách thêm các hàng này vào cuối Utility Matrix.\n",
    "        Để cho đơn giản, giả sử rằng không có users hay items mới, cũng không có ratings nào bị thay đổi.\n",
    "        \"\"\"\n",
    "        self.Y_data = np.concatenate((self.Y_data, new_data), axis = 0)\n",
    "    #Tính toán normalized utility matrix và Similarity matrix\n",
    "    def normalize_Y(self):\n",
    "        users = self.Y_data[:, 0] # all users - first col of the Y_data\n",
    "        self.Ybar_data = self.Y_data.copy()\n",
    "        self.mu = np.zeros((self.n_users,))\n",
    "        for n in range(self.n_users):\n",
    "            # row indices of rating done by user n\n",
    "            # since indices need to be integers, we need to convert\n",
    "            ids = np.where(users == n)[0].astype(np.int32)\n",
    "            # indices of all ratings associated with user n\n",
    "            item_ids = self.Y_data[ids, 1] \n",
    "            # and the corresponding ratings \n",
    "            ratings = self.Y_data[ids, 2]\n",
    "            # take mean\n",
    "            m = np.mean(ratings) \n",
    "            if np.isnan(m):\n",
    "                m = 0 # to avoid empty array and nan value\n",
    "            self.mu[n] = m\n",
    "            # normalize\n",
    "            self.Ybar_data[ids, 2] = ratings - self.mu[n]\n",
    "\n",
    "        ################################################\n",
    "        # form the rating matrix as a sparse matrix. Sparsity is important \n",
    "        # for both memory and computing efficiency. For example, if #user = 1M, \n",
    "        # #item = 100k, then shape of the rating matrix would be (100k, 1M), \n",
    "        # you may not have enough memory to store this. Then, instead, we store \n",
    "        # nonzeros only, and, of course, their locations.\n",
    "        self.Ybar = sparse.coo_matrix((self.Ybar_data[:, 2],\n",
    "            (self.Ybar_data[:, 1], self.Ybar_data[:, 0])), (self.n_items, self.n_users))\n",
    "        self.Ybar = self.Ybar.tocsr()\n",
    "\n",
    "    def similarity(self):\n",
    "        eps = 1e-6\n",
    "        self.S = self.dist_func(self.Ybar.T, self.Ybar.T)\n",
    "    \n",
    "    #Thực hiện lại 2 hàm phía trên khi có thêm dữ liệu.\n",
    "    def refresh(self):\n",
    "        \"\"\"\n",
    "        Normalize data and calculate similarity matrix again (after\n",
    "        some few ratings added)\n",
    "        \"\"\"\n",
    "        self.normalize_Y()\n",
    "        self.similarity() \n",
    "        \n",
    "    def fit(self):\n",
    "        self.refresh()\n",
    "        \n",
    "    #Dự đoán kết quả:\n",
    "    '''\n",
    "        Hàm __pred là hàm dự đoán rating mà user u cho item i cho trường hợp User-user CF. \n",
    "        Vì trong trường hợp Item-item CF, chúng ta cần hiểu ngược lại nên hàm pred sẽ thực hiện đổi vị trí hai biến của __pred. \n",
    "        Để cho API được đơn giản, tôi cho __pred là một phương thức private, chỉ được gọi trong class CF; \n",
    "        pred là một phương thức public,\n",
    "        thứ tự của biến đầu vào luôn là (user, item), bất kể phương pháp sử dụng là User-user CF hay Item-item CF.\n",
    "    '''\n",
    "    def __pred(self, u, i, normalized = 1):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        # Step 1: find all users who rated i\n",
    "        ids = np.where(self.Y_data[:, 1] == i)[0].astype(np.int32)\n",
    "        # Step 2: \n",
    "        users_rated_i = (self.Y_data[ids, 0]).astype(np.int32)\n",
    "        # Step 3: find similarity btw the current user and others \n",
    "        # who already rated i\n",
    "        sim = self.S[u, users_rated_i]\n",
    "        # Step 4: find the k most similarity users\n",
    "        a = np.argsort(sim)[-self.k:] \n",
    "        # and the corresponding similarity levels\n",
    "        nearest_s = sim[a]\n",
    "        # How did each of 'near' users rated item i\n",
    "        r = self.Ybar[i, users_rated_i[a]]\n",
    "        if normalized:\n",
    "            # add a small number, for instance, 1e-8, to avoid dividing by 0\n",
    "            return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8)\n",
    "\n",
    "        return (r*nearest_s)[0]/(np.abs(nearest_s).sum() + 1e-8) + self.mu[u]\n",
    "    \n",
    "    def pred(self, u, i, normalized = 1):\n",
    "        \"\"\" \n",
    "        predict the rating of user u for item i (normalized)\n",
    "        if you need the un\n",
    "        \"\"\"\n",
    "        if self.uuCF: return self.__pred(u, i, normalized)\n",
    "        return self.__pred(i, u, normalized)\n",
    "            \n",
    "    '''\n",
    "    Tìm tất cả các items nên được gợi ý cho user u trong trường hợp User-user CF,\n",
    "    hoặc tìm tất cả các users có khả năng thích item u trong trường hợp Item-item CF\n",
    "    '''\n",
    "    def recommend(self, u):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u.\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which \n",
    "        have not been rated by u yet. \n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist()              \n",
    "        recommended_items = []\n",
    "        for i in xrange(self.n_items):\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.__pred(u, i)\n",
    "                if rating > 0: \n",
    "                    recommended_items.append(i)\n",
    "        \n",
    "        return recommended_items \n",
    "    \n",
    "    def recommend2(self, u):\n",
    "        \"\"\"\n",
    "        Determine all items should be recommended for user u.\n",
    "        The decision is made based on all i such that:\n",
    "        self.pred(u, i) > 0. Suppose we are considering items which \n",
    "        have not been rated by u yet. \n",
    "        \"\"\"\n",
    "        ids = np.where(self.Y_data[:, 0] == u)[0]\n",
    "        items_rated_by_u = self.Y_data[ids, 1].tolist()              \n",
    "        recommended_items = []\n",
    "    \n",
    "        for i in xrange(self.n_items):\n",
    "            if i not in items_rated_by_u:\n",
    "                rating = self.__pred(u, i)\n",
    "                if rating > 0: \n",
    "                    recommended_items.append(i)\n",
    "        \n",
    "        return recommended_items \n",
    "\n",
    "    def print_recommendation(self):\n",
    "        \"\"\"\n",
    "        print all items which should be recommended for each user \n",
    "        \"\"\"\n",
    "        print('Recommendation: ')\n",
    "        for u in range(self.n_users):\n",
    "            recommended_items = self.recommend(u)\n",
    "            if self.uuCF:\n",
    "                print(' Recommend item(s):', recommended_items, 'for user', u)\n",
    "            else: \n",
    "                print(' Recommend item', u, 'for user(s) : ', recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta cùng quay lại làm với cơ sở dữ liệu MoiveLens 100k như trong Content-based Recommendation Systems. Nhắc lại rằng kết quả của phương pháp này có trung bình lỗi là 1.2 sao với mỗi rating.\n",
    "\n",
    "Chúng ta cùng xem kết quả với User-user CF và Item-item CF.\n",
    "\n",
    "Trước hết, ta cần load dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ub.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ub.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "\n",
    "rate_train = ratings_base\n",
    "rate_test = ratings_test\n",
    "\n",
    "# indices start from 0\n",
    "rate_train.iloc[:, :2] -= 1\n",
    "rate_test.iloc[:, :2] -= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kết quả với User-user cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-user CF, RMSE = 0.9959828811717598\n"
     ]
    }
   ],
   "source": [
    "rs = CF(rate_train.values, k = 50, uuCF = 1)\n",
    "rs.fit()\n",
    "\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test.iloc[n, 0], rate_test.iloc[n, 1], normalized = 0)\n",
    "    SE += (pred - rate_test.iloc[n, 2])**2 \n",
    "\n",
    "RMSE = math.sqrt(SE/n_tests)\n",
    "print('User-user CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kết quả với Item-item cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-item CF, RMSE = 0.990340104487686\n"
     ]
    }
   ],
   "source": [
    "rs = CF(rate_train.values, k = 55, uuCF = 0)\n",
    "rs.fit()\n",
    "\n",
    "n_tests = rate_test.shape[0]\n",
    "SE = 0 # squared error\n",
    "for n in range(n_tests):\n",
    "    pred = rs.pred(rate_test.iloc[n, 0], rate_test.iloc[n, 1], normalized = 0)\n",
    "    SE += (pred - rate_test.iloc[n, 2])**2 \n",
    "\n",
    "RMSE = np.sqrt(SE/n_tests)\n",
    "print('Item-item CF, RMSE =', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
